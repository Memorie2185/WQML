# -*- coding: utf-8 -*-
"""Model Choose.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RLohNUGC1qWZfmM2zpbfG2tUWAwMOeNl
"""

from google.colab import drive
drive.mount('/content/drive')

!ls

!ls /content/drive/MyDrive/Colab_Notebooks/water_potability.csv

import pandas as pd
df=pd.read_csv("/content/drive/MyDrive/Colab_Notebooks/water_potability.csv")

df.head()

df.info()

#Mendefenisikan potability sebagai target klasifikasi dan prediksi dengan jenis 'categoring'
df['Potability']=df['Potability'].astype('category')

# membuat batasan nilai minimum dan maksimum untuk setiap kolom yang ada di dalam dataset
cols=df.columns[0:9].to_list()
min_val=[6.52,0,500,0,3,0,0,0,0]
max_val=[6.83,0,1000,4,250,400,2,80,5]
limit=pd.DataFrame(data=[min_val, max_val], columns=cols)

#menghitung nilai mean, standar deviasi, min dan max
df.describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='PuBu')

#Jika Portability is 1 - artinya memenuhi kriteria air minum yang layak untuk manusia
df[df['Potability']==1].describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='PuBu')

# Jika Portability is 0 - artinya tidak memenuhi kriteria air minum yang layak untuk manusia
df[df['Potability']==0].describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='RdBu')

df.isnull().sum()
#Terdapat missing value pada ph, Sulfate, dan Trihalomethanes

#Cek kembali missing value dan menggantinya dengan keterangan Nan
df[df['Sulfate'].isnull()]
df[df['ph'].isnull()]
df[df['Trihalomethanes'].isnull()]

#Selama missing value masih berada pada range potability (0 dan 1), kita dapat menggantinya dengan nilai mean untuk setiap komponen
df['ph']=df['ph'].fillna(df.groupby(['Potability'])['ph'].transform('mean'))
df['Sulfate']=df['Sulfate'].fillna(df.groupby(['Potability'])['Sulfate'].transform('mean'))
df['Trihalomethanes']=df['Trihalomethanes'].fillna(df.groupby(['Potability'])['Trihalomethanes'].transform('mean'))

#Cek hasil input mean pada missing value
df.isna().sum()
#Hasil menunjukkan tidak ada lagi missing value pada setiap komponen

df.describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='PuBu')

#Menangani imbalance pada data dan skala
import imblearn
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
samp = SMOTE()
X=df.drop(['Potability'], axis=1)
y=df['Potability']
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
X_train,X_test, y_train, y_test = train_test_split(X, y, random_state=42)
X_train, y_train =samp.fit_resample(X_train,y_train)

scale = StandardScaler()
X_train=scale.fit_transform(X_train)
X_test=scale.transform(X_test)

#Analisis keakuratan jenis klasifikasi
from yellowbrick.classifier import ROCAUC
from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
mod = []
cv_score=[]
model =[AdaBoostClassifier(), BaggingClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), ExtraTreeClassifier(), KNeighborsClassifier()]
for m in model:
    cv_score.append(cross_val_score(m, X_train, y_train, scoring='accuracy', cv=5).mean())
    mod.append(m)
model_df=pd.DataFrame(columns=['model','cv_score'])
model_df['model']=mod
model_df['cv_score']=cv_score
model_df.sort_values(by=['cv_score'], ascending=True).style.background_gradient(subset=['cv_score'])

#sempurnakan bagging dan gradient boosting
param={'n_estimators': [60,70,80,100,200,300,400,500,600,700]}
grid_Grd=GridSearchCV(GradientBoostingClassifier(), param_grid=param, cv=5, scoring='accuracy')
grid_Grd.fit(X_train, y_train)
print(f"Best Estimator: {grid_Grd.best_params_} , Best Score : {grid_Grd.best_score_}")

param={'n_estimators': [60,70,80,100,200,300,400,500,600,700]}
grid_Bag=GridSearchCV(BaggingClassifier(), param_grid=param, cv=5, scoring='accuracy')
grid_Bag.fit(X_train, y_train)
print(f"Best Estimator: {grid_Bag.best_params_} , Best Score : {grid_Bag.best_score_}")

#Gradient Boosting
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
model = GradientBoostingClassifier(n_estimators=300)
model.fit(X_train,y_train)
pred = model.predict(X_test)
print(classification_report(y_test, pred))
sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='.2f')

#Bagging Classifier
from sklearn.metrics import classification_report, confusion_matrix
model = BaggingClassifier(n_estimators=80)
model.fit(X_train,y_train)
pred = model.predict(X_test)
print(classification_report(y_test, pred))
sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='.2f')

!apt-get install openjdk-8-jdk

!java -version

!pip install H2O

#Model H2O AutoML
import h2o
from h2o.automl import H2OAutoML
h2o.init(max_mem_size=None)

#Running model H2O
h2o_df = h2o.H2OFrame(df)
h2o_df['Potability']=h2o_df['Potability'].asfactor()
X=h2o_df.columns[0:-1]
y=h2o_df.columns[-1]

train, test=h2o_df.split_frame(ratios=[.7])
print(train.nrows)
print(test.nrows)

aml = H2OAutoML(balance_classes=True)
aml.train(x=X, y=y, training_frame=train)

aml.leaderboard

type(test['Potability'])

pred = aml.leader.predict(test)
y_val = h2o.as_list(test['Potability'], use_pandas=True)
pred_val = h2o.as_list(pred['predict'], use_pandas=True)
print(classification_report(y_val,pred_val))